{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adolescent-standard",
   "metadata": {},
   "source": [
    "# Generate some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forward-incidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import numpy as np\n",
    "from iced import io\n",
    "import iced\n",
    "\n",
    "from pastis import optimization\n",
    "from pastis import _dispersion as dispersion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verified-correction",
   "metadata": {},
   "source": [
    "First, load the contact count map and normalize it. We filter rows and columns\n",
    "that are in the bottom 4% of interacting loci prior to applying ICE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "healthy-merit",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_filename = \"./data/rao2014/250kb/HIC_075_250000_chr01.matrix\"\n",
    "\n",
    "counts = io.load_counts(counts_filename)\n",
    "\n",
    "counts = iced.filter.filter_low_counts(\n",
    "    counts, percentage=0.04,\n",
    "    sparsity=False)\n",
    "normed_counts, bias = iced.normalization.ICE_normalization(\n",
    "    counts, output_bias=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indirect-subcommittee",
   "metadata": {},
   "source": [
    "Let's visualize the raw contact counts and the normalized contact counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-forty",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, tight_layout=True)\n",
    "\n",
    "# For visualization purposes, convert the matrix to the dense format and make\n",
    "# it symmetric\n",
    "vis_counts = counts.A\n",
    "vis_counts = vis_counts + vis_counts.T - np.diag(np.diag(vis_counts))\n",
    "axes[0].matshow(vis_counts, norm=colors.SymLogNorm(1))\n",
    "\n",
    "# Do the same for normalized contact counts\n",
    "vis_counts = normed_counts.A\n",
    "vis_counts = vis_counts + vis_counts.T - np.diag(np.diag(vis_counts))\n",
    "axes[1].matshow(vis_counts, norm=colors.SymLogNorm(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "headed-mount",
   "metadata": {},
   "source": [
    "Now, infer a structure for the data using MDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "declared-crisis",
   "metadata": {},
   "outputs": [],
   "source": [
    "mds = optimization.MDS(random_state=0)\n",
    "# By default, there are some NaN in normed_counts. Remove them and replace\n",
    "# them with 0\n",
    "normed_counts.eliminate_zeros()\n",
    "normed_counts = normed_counts.tocoo()\n",
    "\n",
    "X = mds.fit(np.triu(normed_counts.A, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anonymous-palestinian",
   "metadata": {},
   "source": [
    "And infer the dispersion parameter from the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solid-baseline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the dispersion parameter the dispersion parameter\n",
    "dispersion_ = dispersion.ExponentialDispersion(degree=0)\n",
    "\n",
    "_, mean, variance, _ = dispersion.compute_mean_variance(\n",
    "    ori_counts, lengths, bias=bias)\n",
    "dispersion_.fit(mean, variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assigned-macintosh",
   "metadata": {},
   "source": [
    "Now, let's generate a dataset from X. First define some options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funded-contrast",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "beta = 0.5\n",
    "dispersion_factor = 1\n",
    "alpha = -3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-instruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "nreads = counts.sum() # Number of reads in the original dataset.\n",
    "# X_true, sim_counts = create_generated_datasets(\n",
    "#    counts, lengths,\n",
    "#    X,\n",
    "#    dispersion=dispersion_,\n",
    "#    random_state=seed,\n",
    "#    beta=None, alpha=alpha, nreads=beta * nreads)\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "source_map": [
   10,
   16,
   26,
   31,
   41,
   45,
   58,
   62,
   70,
   73,
   80,
   85,
   93
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}